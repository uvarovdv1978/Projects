# -*- coding: utf-8 -*-
"""Диплом_Уваров_Д_DSL_15.ipynb"

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XdNxjy3uFK-m28yNnhkQQ7Ymda1Qxjqv
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import time
import glob

from tqdm.notebook import tqdm
from collections import defaultdict

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split

import torch
from torch import nn
import torch.nn.functional as F
from torchsummary import summary

import torchvision
from torchvision import transforms
import torchvision as tv

from IPython.display import clear_output
# %matplotlib inline

sns.set(font_scale=1.2)
import pickle
from sklearn.preprocessing import LabelEncoder

"""### Загрузим датасет

Познакомимся с датасетом Симпсонов! Там собраны знакомые многим персонажи знаменитого мультфильма для решения задачи классификации.
"""

# загрузим датасет со своего Google Drive

from google.colab import drive

drive.mount("/content/drive")

!mkdir -p data

!cp drive/MyDrive/netology_diplom_work/dataset.zip data/
!cp drive/MyDrive/netology_diplom_work/test_data.zip data/
!unzip -o -qq data/test_data.zip -d data/
!unzip -o -qq data/dataset.zip -d data/
!rm -rf data/simpsons_dataset/simpsons_dataset_small

"""Все данные теперь находятся в папке `data`.



Структура данных (`simpsons_datase_small/`) следующая:


 \\
-- class_name_0 \\
---- img_0 \\
---- img_1 \\
---- ... \\
---- img_n \\
... \\
-- class_name_k \\
---- img_0 \\
---- img_1 \\
---- ... \\
---- img_m \\


Т.е. название папки -- имя класса (действие персонажа из Симпсонов), изображения в ней относятся к этому классу.
"""

# разделим картинки на train и val в отношении 80 на 20 для каждого класса
test_dir = "data/test_data/test"
data_dir = "data/simpsons_dataset_small"

data_image_paths = glob.glob(f"{data_dir}/*/*.jpg")
data_image_labels = [path.split('/')[-2] for path in data_image_paths]
label_encoder = LabelEncoder()
labels = label_encoder.fit_transform(data_image_labels)

train_files_path, val_files_path = train_test_split(
    data_image_paths,
    test_size=0.2,
    stratify=labels
)

print(
    f"Изображений в train: {len(train_files_path)}\nИзображений в val: {len(val_files_path)}"
)

#преобразуем названия классов  в цифровые значания
pca = LabelEncoder()
X_transformed = pca.fit_transform(data_image_labels)

# Transform back to original space
X_original = pca.inverse_transform(X_transformed)
X_unique=list(set(X_original))
X_trans_unique=list(set(X_transformed))
X_original_dict = pca.inverse_transform(X_trans_unique)

print(X_trans_unique)
print(X_original_dict)

"""В случае описанного выше строения хранящихся данных для создания датасета очень удобен `ImageFolder`.

Хоть авторы библиотеки это и не задумывали, но аргумент `is_valid_file` нам пригодился для разбиения на `train` и `val`.
"""

device = "cuda" if torch.cuda.is_available() else "cpu"
device

# оптимизируем фрагментацию видео памяти
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "max_split_size_mb:24"

input_size = 224 # задаем значение в соответствие с параметрами выбранной модели

train_transform = transforms.Compose([
    transforms.Resize(input_size),
    transforms.RandomHorizontalFlip(p=1),
    transforms.CenterCrop(input_size),
    transforms.ColorJitter(0.9, 0.9, 0.9),
    #transforms.RandomAffine(5),# привносит слишком сильные искажения и в итоге мешает модели обучиться
    transforms.ToTensor(),
])


val_transform = transforms.Compose([
    transforms.Resize(input_size),
    transforms.CenterCrop(input_size),
    transforms.ToTensor(),
])

test_transform = transforms.Compose([
    transforms.Resize(input_size),
    transforms.CenterCrop(input_size),
    transforms.ToTensor(),
])

train_dataset = tv.datasets.ImageFolder(
    data_dir,
    transform=train_transform,
    is_valid_file=lambda x: x in train_files_path
)

val_dataset = tv.datasets.ImageFolder(
    data_dir,
    transform=val_transform,
    is_valid_file=lambda x: x in val_files_path
)

test_dataset = tv.datasets.ImageFolder(
    test_dir,
    transform=test_transform)

print("Количество классов в train: ", len(train_dataset.classes))
print("Количество классов в val: ", len(val_dataset.classes))
print("Количество классов одинаково: ", len(train_dataset.classes) == len(val_dataset.classes))

"""Посмотрим на изображения из `val` и `train`"""

sns.set_style(style='white')

def show_images(dataset):
    fig, ax = plt.subplots(
        nrows=2, ncols=3, figsize=(8, 6),
        sharey=True, sharex=True
    )

    for fig_x in ax.flatten():
        idx = np.random.randint(low=0, high=30)
        img, label = dataset[idx]
        fig_x.set_title(dataset.classes[label])
        fig_x.imshow(img.numpy().transpose((1, 2, 0)))

show_images(val_dataset) # пример валидационных изображений

show_images(train_dataset) # пример аугментированных изображений для обучения

"""Невооруженным взглядом видно, что картинки из `train` выглядят немного изменёнными по сравнению с `val`. Опишем по пунктам, почему так происходит.

1. К `train` применялись дополнительные аугментации, чтобы увеличить размер датасета и обобщающую способность сети.
2. К `val` никакие меняющие изображение аугментации не применялись, т.к. замерять метрику качества необходимо на настоящих данных.
"""

show_images(test_dataset)

def plot_learning_curves(history):
    '''
    Функция для вывода графиков лосса и метрики во время обучения.
    '''
    fig = plt.figure(figsize=(20, 7))

    plt.subplot(1,2,1)
    plt.title('Потери', fontsize=15)
    plt.plot(history['loss']['train'], label='train')
    plt.plot(history['loss']['val'], label='val')
    plt.ylabel('потери', fontsize=15)
    plt.xlabel('эпоха', fontsize=15)
    plt.legend()

    plt.subplot(1,2,2)
    plt.title('Точность', fontsize=15)
    plt.plot(history['acc']['train'], label='train')
    plt.plot(history['acc']['val'], label='val')
    plt.ylabel('точность', fontsize=15)
    plt.xlabel('эпоха', fontsize=15)
    plt.legend()
    plt.show()

def train(
    model,
    criterion,
    optimizer,
    train_batch_gen,
    val_batch_gen,
    num_epochs=10
):
    '''
    Функция для обучения модели и вывода лосса и метрики во время обучения.
    '''

    history = defaultdict(lambda: defaultdict(list))

    for epoch in range(num_epochs):
        train_loss = 0
        train_acc = 0
        val_loss = 0
        val_acc = 0

        start_time = time.time()

        # устанавливаем поведение dropout / batch_norm  в обучение
        model.train(True)

        # на каждой "эпохе" делаем полный проход по данным
        for X_batch, y_batch in train_batch_gen:
            # обучаемся на текущем батче
            X_batch = X_batch.to(device)
            y_batch = y_batch.to(device)

            logits = model(X_batch)

            loss = criterion(logits, y_batch.long().to(device))

            loss.backward()
            optimizer.step()
            optimizer.zero_grad()

            train_loss += np.sum(loss.detach().cpu().numpy())
            y_pred = logits.max(1)[1].detach().cpu().numpy()
            train_acc += np.mean(y_batch.cpu().numpy() == y_pred)

        # подсчитываем лоссы и сохраням в "историю"
        train_loss /= len(train_batch_gen)
        train_acc /= len(train_batch_gen)
        history['loss']['train'].append(train_loss)
        history['acc']['train'].append(train_acc)

        # устанавливаем поведение dropout / batch_norm в режим тестирования
        model.train(False)

        # полностью проходим по валидационному датасету
        for X_batch, y_batch in val_batch_gen:
            X_batch = X_batch.to(device)
            y_batch = y_batch.to(device)

            logits = model(X_batch)
            loss = criterion(logits, y_batch.long().to(device))
            val_loss += np.sum(loss.detach().cpu().numpy())
            y_pred = logits.max(1)[1].detach().cpu().numpy()
            val_acc += np.mean(y_batch.cpu().numpy() == y_pred)

        # подсчитываем лоссы и сохраням в "историю"
        val_loss /= len(val_batch_gen)
        val_acc /= len(val_batch_gen)
        history['loss']['val'].append(val_loss)
        history['acc']['val'].append(val_acc)

        clear_output()

        # печатаем результаты после каждой эпохи
        print("Epoch {} of {} took {:.3f}s".format(
            epoch + 1, num_epochs, time.time() - start_time))
        print("  training loss (in-iteration): \t{:.6f}".format(train_loss))
        print("  validation loss (in-iteration): \t{:.6f}".format(val_loss))
        print("  training accuracy: \t\t\t{:.2f} %".format(train_acc * 100))
        print("  validation accuracy: \t\t\t{:.2f} %".format(val_acc * 100))

        plot_learning_curves(history)

    return model, history

"""# VGG-16"""

model = tv.models.vgg16('IMAGENET1K_V1')

"""Начнем эксперимент с применения fine tuning и sheduler StepLR"""

batch_size = 32

# не забудем перемешать train
train_batch_gen = torch.utils.data.DataLoader(
    train_dataset, batch_size=batch_size, shuffle=True
)

fine_tuning_model = nn.Sequential()

fine_tuning_model.add_module('vgg16', model)

# добавим новые слои для классификации для нашей конкретной задачи
fine_tuning_model.add_module('relu_1', nn.ReLU())
fine_tuning_model.add_module('fc_1', nn.Linear(1000, 512))
fine_tuning_model.add_module('relu_2', nn.ReLU())
fine_tuning_model.add_module('fc_2', nn.Linear(512, 13))

fine_tuning_model = fine_tuning_model.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(fine_tuning_model.parameters(), lr=0.01)
#optimizer = torch.optim.Adam(fine_tuning_model.parameters(), lr=0.01)
#scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.001, max_lr=0.01)
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5)
clf_model, history = train(
    fine_tuning_model, criterion, optimizer,
    train_batch_gen, val_batch_gen,
    num_epochs=11
)

"""Наблюдается переобучение модели"""

batch_size = 32

# не забудем перемешать train
train_batch_gen = torch.utils.data.DataLoader(
    train_dataset, batch_size=batch_size, shuffle=True
)
# валидационный датасет мешать не нужно, а точнее бессмысленно
# сеть на нём не обучается
val_batch_gen = torch.utils.data.DataLoader(
    val_dataset, batch_size=batch_size, shuffle=False
)
fine_tuning_model = nn.Sequential()

fine_tuning_model.add_module('vgg16', model)

# добавим новые слои для классификации для нашей конкретной задачи
fine_tuning_model.add_module('relu_1', nn.ReLU())
fine_tuning_model.add_module('fc_1', nn.Linear(1000, 512))
fine_tuning_model.add_module('relu_2', nn.ReLU())
fine_tuning_model.add_module('fc_2', nn.Linear(512, 13))

fine_tuning_model = fine_tuning_model.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(fine_tuning_model.parameters(), lr=0.01)
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=9)
clf_model, history = train(
    fine_tuning_model, criterion, optimizer,
    train_batch_gen, val_batch_gen,
    num_epochs=20
)

"""По прежнему наблюдается переобучение

Попробуем изменить скорость обучения увеличив скорость обучения модели LR = 0.1
"""

batch_size = 32

# не забудем перемешать train
train_batch_gen = torch.utils.data.DataLoader(
    train_dataset, batch_size=batch_size, shuffle=True
)
# валидационный датасет мешать не нужно, а точнее бессмысленно
# сеть на нём не обучается
val_batch_gen = torch.utils.data.DataLoader(
    val_dataset, batch_size=batch_size, shuffle=False
)
fine_tuning_model = nn.Sequential()

fine_tuning_model.add_module('vgg16', model)

# добавим новые слои для классификации для нашей конкретной задачи
fine_tuning_model.add_module('relu_1', nn.ReLU())
fine_tuning_model.add_module('fc_1', nn.Linear(1000, 512))
fine_tuning_model.add_module('relu_2', nn.ReLU())
fine_tuning_model.add_module('fc_2', nn.Linear(512, 13))

fine_tuning_model = fine_tuning_model.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(fine_tuning_model.parameters(), lr=0.1) # Ускорили обучение
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=6)
clf_model, history = train(
    fine_tuning_model, criterion, optimizer,
    train_batch_gen, val_batch_gen,
    num_epochs=20
)

"""Не удачный эксперимент модель не обучилась

Попробуем изменить скорость обучения LR замедлив обучение модели LR = 0.001
"""

batch_size = 32

# не забудем перемешать train
train_batch_gen = torch.utils.data.DataLoader(
    train_dataset, batch_size=batch_size, shuffle=True
)
# валидационный датасет мешать не нужно, а точнее бессмысленно
# сеть на нём не обучается
val_batch_gen = torch.utils.data.DataLoader(
    val_dataset, batch_size=batch_size, shuffle=False
)
fine_tuning_model = nn.Sequential()

fine_tuning_model.add_module('vgg16', model)

# добавим новые слои для классификации для нашей конкретной задачи
fine_tuning_model.add_module('relu_1', nn.ReLU())
fine_tuning_model.add_module('fc_1', nn.Linear(1000, 512))
fine_tuning_model.add_module('relu_2', nn.ReLU())
fine_tuning_model.add_module('fc_2', nn.Linear(512, 13))

fine_tuning_model = fine_tuning_model.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(fine_tuning_model.parameters(), lr=0.001) # замедлили скорость обучения
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5)
clf_model, history = train(
    fine_tuning_model, criterion, optimizer,
    train_batch_gen, val_batch_gen,
    num_epochs=20
)

"""Переобучение стало меньше, но точность на валидации по прежнему слабая

поэксперементируем со step_size
"""

batch_size = 32

# не забудем перемешать train
train_batch_gen = torch.utils.data.DataLoader(
    train_dataset, batch_size=batch_size, shuffle=True
)
# валидационный датасет мешать не нужно, а точнее бессмысленно
# сеть на нём не обучается
val_batch_gen = torch.utils.data.DataLoader(
    val_dataset, batch_size=batch_size, shuffle=False
)
fine_tuning_model = nn.Sequential()

fine_tuning_model.add_module('vgg16', model)

# добавим новые слои для классификации для нашей конкретной задачи
fine_tuning_model.add_module('relu_1', nn.ReLU())
fine_tuning_model.add_module('fc_1', nn.Linear(1000, 512))
fine_tuning_model.add_module('relu_2', nn.ReLU())
fine_tuning_model.add_module('fc_2', nn.Linear(512, 13))

fine_tuning_model = fine_tuning_model.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(fine_tuning_model.parameters(), lr=0.001)
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10)
clf_model, history = train(
    fine_tuning_model, criterion, optimizer,
    train_batch_gen, val_batch_gen,
    num_epochs=20
)

"""Значимых различий нет"""

batch_size = 32

# не забудем перемешать train
train_batch_gen = torch.utils.data.DataLoader(
    train_dataset, batch_size=batch_size, shuffle=True
)
# валидационный датасет мешать не нужно, а точнее бессмысленно
# сеть на нём не обучается
val_batch_gen = torch.utils.data.DataLoader(
    val_dataset, batch_size=batch_size, shuffle=False
)
fine_tuning_model = nn.Sequential()

fine_tuning_model.add_module('vgg16', model)

# добавим новые слои для классификации для нашей конкретной задачи
fine_tuning_model.add_module('relu_1', nn.ReLU())
fine_tuning_model.add_module('fc_1', nn.Linear(1000, 512))
fine_tuning_model.add_module('relu_2', nn.ReLU())
fine_tuning_model.add_module('fc_2', nn.Linear(512, 13))

fine_tuning_model = fine_tuning_model.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(fine_tuning_model.parameters(), lr=0.1)
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10)
clf_model, history = train(
    fine_tuning_model, criterion, optimizer,
    train_batch_gen, val_batch_gen,
    num_epochs=30
)

"""Cломали модель) большим количеством эпох и высоким LR

Продолжим эксперимент с применения fine tuning и sheduler CyclicLR
"""

batch_size = 32

# не забудем перемешать train
train_batch_gen = torch.utils.data.DataLoader(
    train_dataset, batch_size=batch_size, shuffle=True
)
# валидационный датасет мешать не нужно, а точнее бессмысленно
# сеть на нём не обучается
val_batch_gen = torch.utils.data.DataLoader(
    val_dataset, batch_size=batch_size, shuffle=False
)
fine_tuning_model = nn.Sequential()

fine_tuning_model.add_module('vgg16', model)

# добавим новые слои для классификации для нашей конкретной задачи
fine_tuning_model.add_module('relu_1', nn.ReLU())
fine_tuning_model.add_module('fc_1', nn.Linear(1000, 512))
fine_tuning_model.add_module('relu_2', nn.ReLU())
fine_tuning_model.add_module('fc_2', nn.Linear(512, 13))

fine_tuning_model = fine_tuning_model.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(fine_tuning_model.parameters(), lr=0.01)
scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.0001, max_lr=0.01)
clf_model, history = train(
    fine_tuning_model, criterion, optimizer,
    train_batch_gen, val_batch_gen,
    num_epochs=30
)

"""Получились на уровне предыдущих экспериментов, но потенциал есть)

Значительное переобучение

Теперь увеличим max_lr
"""

batch_size = 32

# не забудем перемешать train
train_batch_gen = torch.utils.data.DataLoader(
    train_dataset, batch_size=batch_size, shuffle=True
)
# валидационный датасет мешать не нужно, а точнее бессмысленно
# сеть на нём не обучается
val_batch_gen = torch.utils.data.DataLoader(
    val_dataset, batch_size=batch_size, shuffle=False
)
fine_tuning_model = nn.Sequential()

fine_tuning_model.add_module('vgg16', model)

# добавим новые слои для классификации для нашей конкретной задачи
fine_tuning_model.add_module('relu_1', nn.ReLU())
fine_tuning_model.add_module('fc_1', nn.Linear(1000, 512))
fine_tuning_model.add_module('relu_2', nn.ReLU())
fine_tuning_model.add_module('fc_2', nn.Linear(512, 13))

fine_tuning_model = fine_tuning_model.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(fine_tuning_model.parameters(), lr=0.1)
scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.0001, max_lr=0.1)
clf_model, history = train(
    fine_tuning_model, criterion, optimizer,
    train_batch_gen, val_batch_gen,
    num_epochs=20
)

"""Без изменений

Поправим Base_lr
"""

model = tv.models.vgg16(pretrained=True)
batch_size = 32

# не забудем перемешать train
train_batch_gen = torch.utils.data.DataLoader(
    train_dataset, batch_size=batch_size, shuffle=True
)
# валидационный датасет мешать не нужно, а точнее бессмысленно
# сеть на нём не обучается
val_batch_gen = torch.utils.data.DataLoader(
    val_dataset, batch_size=batch_size, shuffle=False
)
fine_tuning_model = nn.Sequential()

fine_tuning_model.add_module('vgg16', model)

# добавим новые слои для классификации для нашей конкретной задачи
fine_tuning_model.add_module('relu_1', nn.ReLU())
fine_tuning_model.add_module('fc_1', nn.Linear(1000, 512))
fine_tuning_model.add_module('relu_2', nn.ReLU())
fine_tuning_model.add_module('fc_2', nn.Linear(512, 13))

fine_tuning_model = fine_tuning_model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(fine_tuning_model.parameters(), lr=0.01)
scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.001, max_lr=0.01)
clf_model, history = train(
    fine_tuning_model, criterion, optimizer,
    train_batch_gen, val_batch_gen,
    num_epochs=20
)

"""Наблюдаем переобучение

# VIT_H_14
"""

model = tv.models.vit_h_14('IMAGENET1K_SWAG_LINEAR_V1')

print(model)

torch.cuda.empty_cache()
batch_size = 24

# не забудем перемешать train
train_batch_gen = torch.utils.data.DataLoader(
    train_dataset, batch_size=batch_size, shuffle=True
)
# валидационный датасет мешать не нужно, а точнее бессмысленно
# сеть на нём не обучается
val_batch_gen = torch.utils.data.DataLoader(
    val_dataset, batch_size=batch_size, shuffle=False
)

fine_tuning_model = nn.Sequential()

fine_tuning_model.add_module('vit_h_14', model)

# добавим новые слои для классификации для нашей конкретной задачи
fine_tuning_model.add_module('relu_1', nn.ReLU())
fine_tuning_model.add_module('fc_1', nn.Linear(1000, 512))
fine_tuning_model.add_module('relu_2', nn.ReLU())
fine_tuning_model.add_module('fc_2', nn.Linear(512, 13))

fine_tuning_model = fine_tuning_model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(fine_tuning_model.parameters(), lr=0.01)
scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.001, max_lr=0.01)
clf_model, history = train(
    fine_tuning_model, criterion, optimizer,
    train_batch_gen, val_batch_gen,
    num_epochs=20
)

torch.cuda.empty_cache()
batch_size = 24

# не забудем перемешать train
train_batch_gen = torch.utils.data.DataLoader(
    train_dataset, batch_size=batch_size, shuffle=True
)
# валидационный датасет мешать не нужно, а точнее бессмысленно
# сеть на нём не обучается
val_batch_gen = torch.utils.data.DataLoader(
    val_dataset, batch_size=batch_size, shuffle=False
)

fine_tuning_model = nn.Sequential()

fine_tuning_model.add_module('vit_h_14', model)

# добавим новые слои для классификации для нашей конкретной задачи
fine_tuning_model.add_module('relu_1', nn.ReLU())
fine_tuning_model.add_module('fc_1', nn.Linear(1000, 512))
fine_tuning_model.add_module('relu_2', nn.ReLU())
fine_tuning_model.add_module('fc_2', nn.Linear(512, 13))

fine_tuning_model = fine_tuning_model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(fine_tuning_model.parameters(), lr=0.01)
scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.001, max_lr=0.01)
clf_model, history = train(
    fine_tuning_model, criterion, optimizer,
    train_batch_gen, val_batch_gen,
    num_epochs=30
)

"""# ResNext101"""

model = tv.models.resnext101_32x8d('IMAGENET1K_V2')

input_size = 232 # меняем значение под модель ResNext

train_transform = transforms.Compose([
    transforms.Resize(input_size),
    transforms.RandomHorizontalFlip(p=1),
    transforms.CenterCrop(input_size),
    transforms.ColorJitter(0.9, 0.9, 0.9),
    #transforms.RandomAffine(5),
    transforms.ToTensor(),
])


val_transform = transforms.Compose([
    transforms.Resize(input_size),
    transforms.CenterCrop(input_size),
    transforms.ToTensor(),
])

test_transform = transforms.Compose([
    transforms.Resize(input_size),
    transforms.CenterCrop(input_size),
    transforms.ToTensor(),
])

train_dataset = tv.datasets.ImageFolder(
    data_dir,
    transform=train_transform,
    is_valid_file=lambda x: x in train_files_path
)

val_dataset = tv.datasets.ImageFolder(
    data_dir,
    transform=val_transform,
    is_valid_file=lambda x: x in val_files_path
)

test_dataset = tv.datasets.ImageFolder(
    test_dir,
    transform=test_transform)#,
    #is_valid_file=lambda x: x in val_files_path
#)

torch.cuda.empty_cache()
batch_size = 24

# не забудем перемешать train
train_batch_gen = torch.utils.data.DataLoader(
    train_dataset, batch_size=batch_size, shuffle=True
)
# валидационный датасет мешать не нужно, а точнее бессмысленно
# сеть на нём не обучается
val_batch_gen = torch.utils.data.DataLoader(
    val_dataset, batch_size=batch_size, shuffle=False
)
fine_tuning_model = nn.Sequential()

fine_tuning_model.add_module('resnext101_32x8d', model)

# добавим новые слои для классификации для нашей конкретной задачи

fine_tuning_model.add_module('relu_1', nn.ReLU())
#fine_tuning_model.add_module('drop_1', nn.Dropout(0.5))
fine_tuning_model.add_module('fc_1', nn.Linear(1000, 512))
fine_tuning_model.add_module('relu_2', nn.ReLU())
fine_tuning_model.add_module('drop_1', nn.Dropout(0.5))
fine_tuning_model.add_module('fc_2', nn.Linear(512, 13))


fine_tuning_model = fine_tuning_model.to(device)

criterion = nn.CrossEntropyLoss()
#optimizer = torch.optim.Adam(fine_tuning_model.parameters(), lr=0.01)
optimizer = torch.optim.SGD(fine_tuning_model.parameters(), lr=0.08)
scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.005, max_lr=0.08)
clf_model, history = train(
    fine_tuning_model, criterion, optimizer,
    train_batch_gen, val_batch_gen,
    num_epochs=12
)

torch.cuda.empty_cache()
batch_size = 24

# не забудем перемешать train
train_batch_gen = torch.utils.data.DataLoader(
    train_dataset, batch_size=batch_size, shuffle=True
)
# валидационный датасет мешать не нужно, а точнее бессмысленно
# сеть на нём не обучается
val_batch_gen = torch.utils.data.DataLoader(
    val_dataset, batch_size=batch_size, shuffle=False
)
fine_tuning_model = nn.Sequential()

fine_tuning_model.add_module('resnext101_32x8d', model)

# добавим новые слои для классификации для нашей конкретной задачи

fine_tuning_model.add_module('relu_1', nn.ReLU())

fine_tuning_model.add_module('fc_1', nn.Linear(1000, 512))
fine_tuning_model.add_module('relu_2', nn.ReLU())
fine_tuning_model.add_module('drop_1', nn.Dropout(0.5))
fine_tuning_model.add_module('fc_2', nn.Linear(512, 13))


fine_tuning_model = fine_tuning_model.to(device)

criterion = nn.CrossEntropyLoss()

optimizer = torch.optim.SGD(fine_tuning_model.parameters(), lr=0.08)
scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.005, max_lr=0.08, mode='triangular2')
clf_model, history = train(
    fine_tuning_model, criterion, optimizer,
    train_batch_gen, val_batch_gen,
    num_epochs=12
)

"""# VIT-L-16"""

model = tv.models.vit_l_16('IMAGENET1K_V1')

input_size = 224 # меняем значение под модель Vit-L-16

train_transform = transforms.Compose([
    transforms.Resize(input_size),
    transforms.RandomHorizontalFlip(p=1),
    transforms.CenterCrop(input_size),
    transforms.ColorJitter(0.9, 0.9, 0.9),
    #transforms.RandomAffine(5),
    transforms.ToTensor(),
])


val_transform = transforms.Compose([
    transforms.Resize(input_size),
    transforms.CenterCrop(input_size),
    transforms.ToTensor(),
])

test_transform = transforms.Compose([
    transforms.Resize(input_size),
    transforms.CenterCrop(input_size),
    transforms.ToTensor(),
])

train_dataset = tv.datasets.ImageFolder(
    data_dir,
    transform=train_transform,
    is_valid_file=lambda x: x in train_files_path
)

val_dataset = tv.datasets.ImageFolder(
    data_dir,
    transform=val_transform,
    is_valid_file=lambda x: x in val_files_path
)

test_dataset = tv.datasets.ImageFolder(
    test_dir,
    transform=test_transform)#,
    #is_valid_file=lambda x: x in val_files_path
#)

torch.cuda.empty_cache()
batch_size = 16

# не забудем перемешать train
train_batch_gen = torch.utils.data.DataLoader(
    train_dataset, batch_size=batch_size, shuffle=True
)
# валидационный датасет мешать не нужно, а точнее бессмысленно
# сеть на нём не обучается
val_batch_gen = torch.utils.data.DataLoader(
    val_dataset, batch_size=batch_size, shuffle=False
)
fine_tuning_model = nn.Sequential()

fine_tuning_model.add_module('vit_l_16', model)

# добавим новые слои для классификации для нашей конкретной задачи

fine_tuning_model.add_module('relu_1', nn.ReLU())
fine_tuning_model.add_module('fc_1', nn.Linear(1000, 512))
fine_tuning_model.add_module('relu_2', nn.ReLU())
fine_tuning_model.add_module('drop_1', nn.Dropout(0.5))
fine_tuning_model.add_module('fc_2', nn.Linear(512, 13))


fine_tuning_model = fine_tuning_model.to(device)

criterion = nn.CrossEntropyLoss()

optimizer = torch.optim.SGD(fine_tuning_model.parameters(), lr=0.08)
scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.002, max_lr=0.08)
clf_model, history = train(
    fine_tuning_model, criterion, optimizer,
    train_batch_gen, val_batch_gen,
    num_epochs=12
)

my_list = history['acc']['val']
my_formatted_list = [ '%.2f' % elem for elem in my_list ]

print(my_formatted_list)

torch.cuda.empty_cache()
batch_size = 18

# не забудем перемешать train
train_batch_gen = torch.utils.data.DataLoader(
    train_dataset, batch_size=batch_size, shuffle=True
)
# валидационный датасет мешать не нужно, а точнее бессмысленно
# сеть на нём не обучается
val_batch_gen = torch.utils.data.DataLoader(
    val_dataset, batch_size=batch_size, shuffle=False
)
fine_tuning_model = nn.Sequential()

fine_tuning_model.add_module('vit_l_16', model)

# добавим новые слои для классификации для нашей конкретной задачи

fine_tuning_model.add_module('relu_1', nn.ReLU())
fine_tuning_model.add_module('fc_1', nn.Linear(1000, 512))
fine_tuning_model.add_module('relu_2', nn.ReLU())
fine_tuning_model.add_module('drop_1', nn.Dropout(0.5))
fine_tuning_model.add_module('fc_2', nn.Linear(512, 13))


fine_tuning_model = fine_tuning_model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(fine_tuning_model.parameters(), lr=0.03)
scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.003, max_lr=0.03)
clf_model, history = train(
    fine_tuning_model, criterion, optimizer,
    train_batch_gen, val_batch_gen,
    num_epochs=20
)

my_list = history['acc']['val']
my_formatted_list = [ '%.2f' % elem for elem in my_list ]

print(my_formatted_list)

torch.cuda.empty_cache()
batch_size = 18

# не забудем перемешать train
train_batch_gen = torch.utils.data.DataLoader(
    train_dataset, batch_size=batch_size, shuffle=True
)
# валидационный датасет мешать не нужно, а точнее бессмысленно
# сеть на нём не обучается
val_batch_gen = torch.utils.data.DataLoader(
    val_dataset, batch_size=batch_size, shuffle=False
)
fine_tuning_model = nn.Sequential()

fine_tuning_model.add_module('vit_l_16', model)

# добавим новые слои для классификации для нашей конкретной задачи

fine_tuning_model.add_module('relu_1', nn.ReLU())
fine_tuning_model.add_module('fc_1', nn.Linear(1000, 512))
fine_tuning_model.add_module('relu_2', nn.ReLU())
#fine_tuning_model.add_module('drop_1', nn.Dropout(0.5))
fine_tuning_model.add_module('fc_2', nn.Linear(512, 13))


fine_tuning_model = fine_tuning_model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(fine_tuning_model.parameters(), lr=0.08)
scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.003, max_lr=0.08, mode='triangular2')
clf_model, history = train(
    fine_tuning_model, criterion, optimizer,
    train_batch_gen, val_batch_gen,
    num_epochs=12
)

#Сохраняем обученную модель
PATH = "/content/model_1.pt"

# Define your model
model = fine_tuning_model

# Save the model
torch.save(model, PATH)



"""# Проверка работы модели"""

#Описываем функцию работы модели по единичному изображению
def predict_one_sample(model, img_tensor, device=device):
    with torch.no_grad():

        img_tensor = img_tensor.to(device)
        model.eval()
        y_hat = model(img_tensor).cpu()
        y_pred = y_hat.max(1)[1].detach().cpu().numpy()

    return y_pred

def show (model,dataset,i):
    im_val, label = dataset[i]

    image = im_val.permute(1,2,0)

    image = image
    plt.imshow(image,cmap = 'gray')

    prob_pred = predict_one_sample(model, im_val.unsqueeze(0))
    label_pred = prob_pred[0]
    print('Предсказание:',(label_encoder.inverse_transform(X_trans_unique)[label_pred]))

model_1 = fine_tuning_model # Модель с качеством обучения 64%

show (model_1,test_dataset,6)

show (model_1,test_dataset,12)

show (model_1,test_dataset,11)

show (model_1,test_dataset,13)

show (model_1,test_dataset,15)

show (model_1,test_dataset,17)

show (model_1,test_dataset,18)

show (model_1,test_dataset,24)

show (model_1,test_dataset,27)

show (model_1,test_dataset,2)

model_1 = fine_tuning_model # Модель с качеством обучения 74%

show (model_1,test_dataset,6)

show (model_1,test_dataset,11)

show (model_1,test_dataset,27)

show (model_1,test_dataset,2)