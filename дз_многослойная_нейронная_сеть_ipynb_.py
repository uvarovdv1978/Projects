# -*- coding: utf-8 -*-
"""ДЗ_Многослойная нейронная сеть.ipynb"

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pporghw9jjcXl1J_zUWxkowr74EwGEOI
"""

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

import torch

import numpy as np

"""## MLP

## Данные
"""

import torchvision as tv

import pandas as pd
import numpy as np

import time

BATCH_SIZE=256



train_dataset = tv.datasets.FashionMNIST('.', train=True, transform=tv.transforms.ToTensor(), download=True)
test_dataset = tv.datasets.FashionMNIST('.', train=False, transform=tv.transforms.ToTensor(), download=True)
train = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)
test = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)

train_dataset[0][0].shape

"""## Модель"""

model = torch.nn.Sequential(
    torch.nn.Flatten(),
    torch.nn.Linear(784, 1568),
    torch.nn.BatchNorm1d(1568),
    torch.nn.ReLU(),
    torch.nn.Linear(1568, 2560),
    torch.nn.BatchNorm1d(2560),
    torch.nn.ReLU(),
    torch.nn.Linear(2560, 1280),
    torch.nn.BatchNorm1d(1280),
    torch.nn.ReLU(),
    torch.nn.Dropout(0.5),
    torch.nn.Linear(1280, 640),
    torch.nn.ReLU(),
    torch.nn.Dropout(0.5),
    torch.nn.Linear(640, 320),
    torch.nn.ReLU(),
    torch.nn.Dropout(0.5),
    torch.nn.Linear(320, 10)
)

model

loss = torch.nn.CrossEntropyLoss()
trainer = torch.optim.SGD(model.parameters(), lr=.01)
num_epochs = 6

import time

def train_model():
    for ep in range(num_epochs):
        train_iters, train_passed  = 0, 0
        train_loss, train_acc = 0., 0.
        start=time.time()

        model.train()
        for X, y in train:
            trainer.zero_grad()
            y_pred = model(X)
            l = loss(y_pred, y)
            l.backward()
            trainer.step()
            train_loss += l.item()
            train_acc += (y_pred.argmax(dim=1) == y).sum().item()
            train_iters += 1
            train_passed += len(X)

        test_iters, test_passed  = 0, 0
        test_loss, test_acc = 0., 0.
        model.eval()
        for X, y in test:
            y_pred = model(X)
            l = loss(y_pred, y)
            test_loss += l.item()
            test_acc += (y_pred.argmax(dim=1) == y).sum().item()
            test_iters += 1
            test_passed += len(X)

        print("ep: {}, taked: {:.3f}, train_loss: {}, train_acc: {}, test_loss: {}, test_acc: {}".format(
            ep, time.time() - start, train_loss / train_iters, train_acc / train_passed,
            test_loss / test_iters, test_acc / test_passed)
        )

trainer = torch.optim.Adam(model.parameters(), lr=.001)
train_model()

trainer = torch.optim.SGD(model.parameters(), lr=.01)
num_epochs = 5
train_model()



model = torch.nn.Sequential(
    torch.nn.Flatten(),
    torch.nn.Linear(784, 1568),
    torch.nn.ReLU(),
    torch.nn.Dropout(0.3),
    torch.nn.Linear(1568, 2560),
    torch.nn.ReLU(),
    torch.nn.Dropout(0.3),
    torch.nn.Linear(2560, 1280),
    torch.nn.ReLU(),
    torch.nn.Dropout(0.5),
    torch.nn.Linear(1280, 640),
    torch.nn.ReLU(),
    torch.nn.Dropout(0.5),
    torch.nn.Linear(640, 320),
    torch.nn.ReLU(),
    torch.nn.Dropout(0.3),
    torch.nn.Linear(320, 10)
)

trainer = torch.optim.Adam(model.parameters(), lr=.001)
train_model()

trainer = torch.optim.SGD(model.parameters(), lr=.01)
train_model()



model = torch.nn.Sequential(
    torch.nn.Flatten(),
    torch.nn.Linear(784, 1568),
    torch.nn.BatchNorm1d(1568),
    torch.nn.ReLU(),
    torch.nn.Linear(1568, 2560),
    torch.nn.BatchNorm1d(2560),
    torch.nn.ReLU(),
    torch.nn.Linear(2560, 1280),
    torch.nn.BatchNorm1d(1280),
    torch.nn.ReLU(),
    torch.nn.Dropout(0.5),
    torch.nn.Linear(1280, 640),
    torch.nn.BatchNorm1d(640),
    torch.nn.ReLU(),
    torch.nn.Dropout(0.5),
    torch.nn.Linear(640, 320),
    torch.nn.BatchNorm1d(320),
    torch.nn.ReLU(),
    torch.nn.Dropout(0.5),
    torch.nn.Linear(320, 10)
)

trainer = torch.optim.Adam(model.parameters(), lr=.001)
train_model()

trainer = torch.optim.SGD(model.parameters(), lr=.01)
train_model()



model = torch.nn.Sequential(
    torch.nn.Flatten(),
    torch.nn.Linear(784, 1568),
    torch.nn.ReLU(),
    torch.nn.BatchNorm1d(1568),
    torch.nn.Linear(1568, 2560),
    torch.nn.ReLU(),
    torch.nn.BatchNorm1d(2560),
    torch.nn.Linear(2560, 1280),
    torch.nn.ReLU(),
    torch.nn.BatchNorm1d(1280),
    torch.nn.Dropout(0.5),
    torch.nn.Linear(1280, 640),
    torch.nn.ReLU(),
    torch.nn.BatchNorm1d(640),
    torch.nn.Dropout(0.5),
    torch.nn.Linear(640, 320),
    torch.nn.ReLU(),
    torch.nn.BatchNorm1d(320),
    torch.nn.Dropout(0.5),
    torch.nn.Linear(320, 10)
)

trainer = torch.optim.Adam(model.parameters(), lr=.001)
train_model()

trainer = torch.optim.SGD(model.parameters(), lr=.01)
train_model()



model = torch.nn.Sequential(
    torch.nn.Flatten(),
    torch.nn.Linear(784, 1568),
    torch.nn.ReLU(),
    torch.nn.BatchNorm1d(1568),
    torch.nn.Linear(1568, 2560),
    torch.nn.ReLU(),
    torch.nn.BatchNorm1d(2560),
    torch.nn.Linear(2560, 1280),
    torch.nn.ReLU(),
    torch.nn.BatchNorm1d(1280),
    torch.nn.Linear(1280, 640),
    torch.nn.ReLU(),
    torch.nn.BatchNorm1d(640),
    torch.nn.Linear(640, 320),
    torch.nn.ReLU(),
    torch.nn.BatchNorm1d(320),
    torch.nn.Linear(320, 10)
)

trainer = torch.optim.Adam(model.parameters(), lr=.001)
train_model()

trainer = torch.optim.SGD(model.parameters(), lr=.01)
train_model()







