# -*- coding: utf-8 -*-
"""ДЗ_ Архитектуры сверточных сетей.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jeKKKSSnJRtSSlAxE8o7pDiRggbGCBoI

## Архитектуры свёрточных сетей
"""

import torch
from torch import nn
import torchvision as tv
from torchsummary import summary
import time
import pandas as pd
#import numpy as np
import matplotlib.pyplot as plt

report = pd.DataFrame(columns=['resnet_18','VGG_16', 'Inception_v3', 'DenseNet_161'])

def evaluate_accuracy(data_iter, net):
    acc_sum, n = 0, 0
    net.eval()
    for X, y in data_iter:
        X, y = X.to(device), y.to(device)
        acc_sum += (net(X).argmax(axis=1) == y).sum()
        n += y.shape[0]
    return acc_sum.item() / n

def train(name, net, train_iter, test_iter, trainer, num_epochs):
    net.to(device)
    loss = nn.CrossEntropyLoss(reduction='sum')
    net.train()
    List_loss = []
    for epoch in range(num_epochs):
        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()

        for i, (X, y) in enumerate(train_iter):
            X, y = X.to(device), y.to(device)
            trainer.zero_grad()
            y_hat = net(X)
            l = loss(y_hat, y)
            l.backward()
            trainer.step()
            train_l_sum += l.item()
            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()
            n += y.shape[0]

            if i % 100 == 0:
                train_loss_f = round((train_l_sum / n), 3)
                train_acc_f = round((train_acc_sum / n)*100, 3)
                print(f"Step {i}. time since epoch: {time.time() -  start:.3f}. "
                    f"Train acc: {train_acc_f:.3f}. Train Loss: {train_loss_f:.3f}")
        test_acc = evaluate_accuracy(test_iter, net.to(device))
        test_acc_final = round(test_acc*100, 3)
        train_acc_final = round((train_acc_sum / n)*100, 3)
        train_loss_final = round((train_l_sum / n), 3)
        List_loss.append(train_loss_final)
        print('-' * 20)
        print(f'epoch {epoch + 1}, loss {train_loss_final:.4f}, train acc {train_acc_final:.3f}'
              f', test acc {test_acc_final:.3f}, time {time.time() - start:.1f} sec')
    report[name] = List_loss
    #report.loc[len(report)] = [name, test_acc_final, (time.time() - start)]

device = 'cuda' if torch.cuda.is_available() else 'cpu'
device

"""## Предобученные архитектуры"""

num_epochs = 10
BATCH_SIZE = 256
transoforms = tv.transforms.Compose([
    tv.transforms.Grayscale(3),
    tv.transforms.Resize((224, 224)),
    tv.transforms.ToTensor()
])

train_dataset = tv.datasets.EMNIST('.', split='balanced', train=True, transform=transoforms, download=True)
test_dataset = tv.datasets.EMNIST('.', split='balanced', train=False, transform=transoforms, download=True)
train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)
test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)

train_dataset.targets.shape

examples = enumerate(train_iter)
batch_idx, (example_data, example_targets) = next(examples)

example_data.shape

import matplotlib.pyplot as plt

fig = plt.figure()
for i in range(6):
  plt.subplot(2,3,i+1)
  plt.tight_layout()
  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')
  plt.title("Ground Truth: {}".format(example_targets[i]))
  plt.xticks([])
  plt.yticks([])
fig

"""#### ResNet"""

model = tv.models.resnet18(pretrained=True)

model

summary(model.to(device), input_size=(3, 224, 224))

# Убираем требование градиента:
for param in model.parameters():
    param.requires_grad = False

model.fc

#model.fc = nn.Linear(in_features=512, out_features=62)
model.fc = nn.Linear(in_features=512, out_features=47)

print("Params to learn:")
params_to_update = []
for name, param in model.named_parameters():
    if param.requires_grad == True:
        params_to_update.append(param)
        print("\t",name)

trainer = torch.optim.Adam(params_to_update, lr=0.001)

train('resnet_18',model, train_iter, test_iter, trainer, num_epochs)

report

"""#### VGG 16"""



model = tv.models.vgg16(pretrained=True)

model

model.classifier

# Убираем требование градиента:
for param in model.parameters():
    param.requires_grad = False

model.classifier = nn.Sequential(
        nn.Linear(25088, 4096), nn.ReLU(), nn.Dropout(0.5),
        #nn.Linear(6272, 4096), nn.ReLU(), nn.Dropout(0.5),
        nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(0.5),
        nn.Linear(4096, 47))

summary(model.to(device), input_size=(3, 224, 224))



print("Params to learn:")
params_to_update = []
for name, param in model.named_parameters():
    if param.requires_grad == True:
        params_to_update.append(param)
        print("\t",name)

trainer = torch.optim.Adam(params_to_update, lr=0.001)

torch.cuda.empty_cache()

#torch.cuda.memory_summary(device=None, abbreviated=False)

train('VGG_16', model, train_iter, test_iter, trainer, num_epochs)

report

#report.to_csv('report.csv', index=False)

#from google.colab import drive
#drive.mount('drive')

#report.to_csv('report1.csv', index=False)
#!cp report1.csv "drive/My Drive/"

report = pd.read_csv('report1.csv')

report

"""#### DenseNet"""

model = tv.models.densenet161(pretrained=True)

model

model.classifier

# Убираем требование градиента:
for param in model.parameters():
    param.requires_grad = False

model.classifier = nn.Linear(in_features=2208, out_features=47)

print("Params to learn:")
params_to_update = []
for name, param in model.named_parameters():
    if param.requires_grad == True:
        params_to_update.append(param)
        print("\t",name)

trainer = torch.optim.Adam(params_to_update, lr=0.01)

torch.cuda.empty_cache()
train('DenseNet_161',model, train_iter, test_iter, trainer, num_epochs)

report

report.to_csv('/content/report3.csv')

report = pd.read_csv('/content/report3.csv')

report

"""#### Inception_v3"""

BATCH_SIZE = 256
transoforms = tv.transforms.Compose([
    tv.transforms.Grayscale(3),
    tv.transforms.Resize((299, 299)),
    tv.transforms.ToTensor()
])

train_dataset = tv.datasets.EMNIST('.', train=True, transform=transoforms, download=True, split='mnist')
test_dataset = tv.datasets.EMNIST('.', train=False, transform=transoforms, download=True, split='mnist')
train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)
test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)

model = tv.models.inception_v3(pretrained=True)
model = model.to(device)

def evaluate_accuracy(data_iter, net):
    acc_sum, n = 0, 0
    net.eval()
    for X, y in data_iter:
        X, y = X.to(device), y.to(device)
        y_hat = net(X)
        acc_sum += (y_hat.argmax(axis=1) == y).sum()
        n += y.shape[0]
        return 0
    return acc_sum.item() / n

def train(name, net, train_iter, test_iter, trainer, num_epochs):
    List_loss = []
    net.to(device)
    loss = nn.CrossEntropyLoss(reduction='sum')
    for epoch in range(num_epochs):
        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()
        net.train()
        for i, (X, y) in enumerate(train_iter):
            X, y = X.to(device), y.to(device)
            trainer.zero_grad()
            y_hat = net(X)
            l = loss(y_hat[0], y)
            l.backward()
            trainer.step()
            train_l_sum += l.item()
            train_acc_sum += (y_hat[0].argmax(axis=1) == y).sum().item()
            n += y.shape[0]
            if i % 100 == 0:
                train_loss_f = round((train_l_sum / n), 3)
                train_acc_f = round((train_acc_sum / n)*100, 3)
                print(f"Step {i}. time since epoch: {time.time() -  start:.3f}. "
                    f"Train acc: {train_acc_f:.3f}. Train Loss: {train_loss_f:.3f}")
        test_acc = evaluate_accuracy(test_iter, net.to(device))
        test_acc_final = round(test_acc*100, 3)
        train_acc_final = round((train_acc_sum / n)*100, 3)
        train_loss_final = round((train_l_sum / n), 3)
        List_loss.append(train_loss_final)
        print('-' * 20)
        print(f'epoch {epoch + 1}, loss {train_loss_final:.4f}, train acc {train_acc_final:.3f}'
              f', test acc {test_acc_final:.3f}, time {time.time() - start:.1f} sec')
    report[name] = List_loss
    #report.loc[len(report)] = [name, test_acc_final, (time.time() - start)]

# Убираем требование градиента:
for param in model.parameters():
    param.requires_grad = False

model.fc = nn.Linear(in_features=2048, out_features=47)

params_to_update = []
for name, param in model.named_parameters():
    if param.requires_grad == True:
        params_to_update.append(param)
        print("\t",name)

trainer = torch.optim.Adam(params_to_update, lr=0.001)

train('Inception_v3', model, train_iter, test_iter, trainer, num_epochs)

report = pd.read_csv('/content/report3.csv')

report # не удалось закончит из-за исчерпания лимито использования GPU Colab